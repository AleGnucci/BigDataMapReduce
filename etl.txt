//apri putty, usa isi-vclust4.csr.unibo.it , con username agnucci

//creazione cartella utente e altre
hdfs dfs -mkdir /user/agnucci
hdfs dfs -mkdir /user/agnucci/datasets
hdfs dfs -mkdir /user/agnucci/outputMR
hdfs dfs -mkdir /user/agnucci/outputSpark

//poi carica i files in una cartella sul cluster con winSCP

//poi vai in quella cartella con il comando cd, dentro alla shell di putty

//caricamento di files su hdfs
hadoop fs -put ./ /user/agnucci/datasets/

//cancellazione di vecchia versione del dataset unito:
hadoop fs -rmr /user/agnucci/datasets/youtubeDataset

//con spark2-shell (unione di files e conversione a parquet):

val sqlContext= new org.apache.spark.sql.SQLContext(sc)
import sqlContext.implicits._
val CArdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/CAvideos.csv")
val DErdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/DEvideos.csv")
val FRrdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/FRvideos.csv")
val GBrdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/GBvideos.csv")
val INrdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/INvideos.csv")
val JPrdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/JPvideos.csv")
val KRrdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/KRvideos.csv")
val MXrdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/MXvideos.csv")
val RUrdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/RUvideos.csv")
val USrdd = sc.textFile("hdfs:/user/agnucci/datasets/youtube-new/USvideos.csv")
val bigRdd = sc.union(Seq(CArdd, DErdd, FRrdd, GBrdd, INrdd, JPrdd, KRrdd, MXrdd, RUrdd, USrdd))
val schema = new StructType()
  .add(StructField("video_id", StringType, true))
  .add(StructField("trending_date", StringType, true))
  .add(StructField("title", StringType, true))
  .add(StructField("channel_title", StringType, true))
  .add(StructField("category_id", IntegerType, true))
  .add(StructField("publish_time", StringType, true))
  .add(StructField("tags", StringType, true))
  .add(StructField("views", LongType, true))
  .add(StructField("likes", LongType, true))
  .add(StructField("dislikes", LongType, true))
  .add(StructField("comment_count", LongType, true))
  .add(StructField("thumbnail_link", StringType, true))
  .add(StructField("comments_disabled", BooleanType, true))
  .add(StructField("ratings_disabled", BooleanType, true))
  .add(StructField("video_error_or_removed", BooleanType, true))
  .add(StructField("description", StringType, true))
val outputRdd = bigRdd.coalesce(1)
spark.createDataFrame(outputRdd, schema).write.parquet("hdfs:/user/agnucci/datasets/youtubeDataset")